% !TEX root = main.tex

\secmoveup
\section{Conclusion}
In this paper, we have shown that by using a carefully selected novel
combination of the latest techniques drawn from multiple sub-fields within
machine learning, we are able to set a new SOTA for news image captioning. Our
model can incorporate real-world knowledge about entities across different
modalities and generate text with better linguistic diversity. The key modeling
components are byte-pair encoding that can output any word, contextualized
embeddings for article text, specialized face \& object encoding, and
transformer-based caption generation. This result provides a promising step for
other image description tasks with contextual knowledge, such as web pages,
social media feeds, or medical documents. Promising future directions include
specialized visual models for a broader set of entities like countries and
organizations, extending the image context from the current article to recent
or linked articles, or designing similar techniques for other image and text
domains.

\secmoveup
\section*{Acknowledgement}

This research was supported in part by the Data to Decisions Cooperative
Research Centre whose activities are funded by the Australian Commonwealth
Governmentâ€™s Cooperative Research Centres Programme. The research was also
supported in part by the Australian Research Council through project number
DP180101985. We thank NVIDIA for providing us with Titan V GPUs through their
GPU Grant Program.


% \eat{simultaneously captioning all images associated with an
% article (eg by encouraging diversity or similarity between captions), and}
